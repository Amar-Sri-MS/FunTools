{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FunOS module initialization analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyze module initilzation, durations and dependencies.\n",
    "Input file is `modules.json`.\n",
    "\n",
    "**References** for the notebook:\n",
    "- [Using simple barh based implementation](https://towardsdatascience.com/gantt-charts-with-pythons-matplotlib-395b7af72d72)\n",
    "- [Barh based with hints on how to make better representation](https://medium.com/geekculture/generate-gantt-chart-in-python-9d1e1fe9103e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- add runner scripts for generate html\n",
    "- update requirement.txt (environiment.yml)\n",
    "- add legend for all\n",
    "- add title for plotly\n",
    "- update ytick for plotly\n",
    "- update color for notif bar plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *NOTE*: run this command to clean output cell and meta data.\n",
    "\n",
    "#nb-clean clean  ./funos_stats_analysis/fun_module_init_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html gen\n",
    "# cd Projects/Fng/FunTools/dpcsh_interactive_client/src\n",
    "# ./dpcsh_interactive_client/convert_nb.py --filename ./funos_stats_analysis/fun_module_init_analysis.ipynb --execute \n",
    "# scp ./funos_stats_analysis/fun_module_init_analysis.html vnc-shared-07:/dogfood/users/insop/html/modules_init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "#https://stackoverflow.com/questions/36288670/how-to-programmatically-generate-markdown-output-in-jupyter-notebooks\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config\n",
    "TODO: need to pass config to APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "current_path = os.getcwd()\n",
    "print(\"current directory is: \"+current_path)\n",
    "\n",
    "config_file = \"funos_module_init_analysis_config.yml\"\n",
    "path_to_yaml = os.path.join(current_path, config_file)\n",
    "print(\"path_to_config_file \"+path_to_yaml)\n",
    "try:\n",
    "    with open (path_to_yaml, 'r') as c_file:\n",
    "        config = yaml.safe_load(c_file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file at {} : {}'.format(path_to_yaml, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config variables\n",
    "# DEBUG = config['general']['debug']\n",
    "# debug_log = config['general']['debug_log']\n",
    "\n",
    "# modules_init_file_name = config['file_names']['input_modules_init']\n",
    "notificaiotns_init_file_name = config['file_names']['input_notifications_init']\n",
    "\n",
    "# full_chart_file_name = config['file_names']['output_full_chart']\n",
    "# full_module_notif_chart = config['file_names']['output_full_module_notif_chart']\n",
    "# collapsed_chart_file_name = config['file_names']['output_collapsed_chart']\n",
    "# collapsed_chart_module_notif_file_name = config['file_names']['output_collapsed_module_notif_chart']\n",
    "# sorted_df_file_name = config['file_names']['output_sorted_df']\n",
    "\n",
    "# module_color = config['chart']['module']\n",
    "# notification_color = config['chart']['notification']\n",
    "\n",
    "notif_suffix = config[\"extra\"][\"notif_suffix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def _fmt(s, show_d=True):\n",
    "    \"\"\"show decimal number with comma\"\"\"\n",
    "    if show_d:\n",
    "        return format(s, \",d\")\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def convert_to_list_of_dicts(raw_data: dict, convert_time_to_ns: bool, debug: bool) -> list:\n",
    "    \"\"\"convert the raw data (dict based format) to list of dicts\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_data : dict\n",
    "        raw data in dict format, module_name: [start_time, end_time]\n",
    "    \n",
    "    convert_time_to_ns : bool, optional\n",
    "        convert time to ns, by default True\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fun_module_init_list : list\n",
    "        list of dicts, each dict is a module, with keys: module_name, start_time, finish_time\n",
    "    \"\"\"\n",
    "    time_unit = 0\n",
    "    if convert_time_to_ns:\n",
    "        time_unit = 1000000000\n",
    "    fun_module_init_list = []\n",
    "    for module_name, module_data in raw_data.items():\n",
    "        temp_dict = {}\n",
    "        temp_dict['module_name'] = module_name\n",
    "        temp_dict['start_time'] = time_unit * float(module_data[0])\n",
    "        temp_dict['finish_time'] = time_unit * float(module_data[1])\n",
    "        # add duration column\n",
    "        temp_dict['module_init_duration'] = temp_dict['finish_time'] - temp_dict['start_time']\n",
    "        fun_module_init_list.append(temp_dict)\n",
    "\n",
    "    if debug:\n",
    "        print(\"List created\")\n",
    "        print(fun_module_init_list[:2])\n",
    "        print(\"Time conversion unit: {}\".format(time_unit))\n",
    "        # convert list of dicts to pandas dataframe\n",
    "        # fun_module_init_df = pd.DataFrame(fun_module_init_list)\n",
    "        # fun_module_init_df.head()\n",
    "    \n",
    "    return fun_module_init_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def load_module_init_data(input_file: str, convert_time_to_ns: bool = True, debug: bool=False) -> pd.DataFrame:\n",
    "    \"\"\"load module init data from json file and convert to pandas dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        input file name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    fun_module_init_df : pd.DataFrame\n",
    "        pandas dataframe with module_name, start_time, finish_time, module_init_duration\n",
    "\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        fun_module_init = json.load(f)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Number of modules: {}\".format(len(fun_module_init)))\n",
    "        print(\"fun_module_init.keys: {}\".format(fun_module_init.keys()))\n",
    "        # print(\"fun_module_init['accel_telem-init']: {}\".format(fun_module_init['accel_telem-init']))\n",
    "\n",
    "    # convert to list of dicts\n",
    "    fun_module_init_list = convert_to_list_of_dicts(fun_module_init, convert_time_to_ns=convert_time_to_ns, debug=debug)\n",
    "\n",
    "    # convert to df\n",
    "    fun_module_init_df = pd.DataFrame(fun_module_init_list)\n",
    "    fun_module_init_df.set_index('module_name', inplace=True)\n",
    "\n",
    "    return fun_module_init_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def load_notification_init_data(input_file: str, convert_time_to_ns: bool = True, dummy_duration: float=1e-1, debug: bool=False) -> pd.DataFrame:\n",
    "    \"\"\"load notificaiton init data from json file and convert to pandas dataframe\n",
    "\n",
    "    notification formation is different than module init data\n",
    "    first load json and modifiy the data to match module init data format\n",
    "    then call load function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        input file name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    fun_module_init_df : pd.DataFrame\n",
    "        pandas dataframe with module_name, start_time, finish_time, module_init_duration\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with open(input_file, 'r') as f:\n",
    "        fun_notification_init = json.load(f)\n",
    "    if debug:\n",
    "        print(fun_notification_init)\n",
    "\n",
    "    new_dict = {}\n",
    "    for k, v in fun_notification_init.items():\n",
    "        ## TEMP, to easily identify\n",
    "        k = \"{}-{}\".format(k, notif_suffix)\n",
    "        new_dict[k] = [v, v+dummy_duration]\n",
    "    if debug:\n",
    "        print(new_dict)\n",
    "    \n",
    "    # save to temp json file\n",
    "    temp_file_name = notificaiotns_init_file_name + '_temp.json'\n",
    "    with open(temp_file_name, 'w') as f:\n",
    "        json.dump(new_dict, f)\n",
    "\n",
    "    fun_notification_init_df = load_module_init_data(temp_file_name, convert_time_to_ns=True, debug=debug)\n",
    "    if debug:\n",
    "        fun_notification_init_df.head()\n",
    "    return fun_notification_init_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def get_duration_threshold(df: pd.DataFrame, threshold: float=0.10) -> float:\n",
    "    \"\"\"Get the threshold value from the dataframe\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    threshold : float, optional\n",
    "        threshold value, by default 0.10\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        threshold value\n",
    "    \"\"\"\n",
    "    max_duration = df['module_init_duration'].max()\n",
    "\n",
    "    return float(int(max_duration * threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def get_start_finish_times(df: pd.DataFrame, debug: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Utility to get start and finish times from df\"\"\"\n",
    "\n",
    "    start_min = df['start_time'].min() # first module start time\n",
    "    finish_max = df['finish_time'].max() # last module finish time\n",
    "    duration = finish_max - start_min # time between the first module start time and last module finish time\n",
    "\n",
    "    if debug:\n",
    "        print(\"start_min (start time of the first module): {}\".format(start_min))\n",
    "        print(\"finish_max: (finish time of the last module) {}\".format(finish_max))\n",
    "        # print(\"duration: (finish_max - start_min) {}\".format(finish_max - start_min))\n",
    "        # summary\n",
    "        total_module_time = df['module_init_duration'].sum()\n",
    "        print(\"Total module init time: {} ns\".format(total_module_time))\n",
    "        print(\"duration (time between the first module start time and last module finish time): {} ns\".format(finish_max - start_min))\n",
    "        print(\"'Total module init time' / 'duration' (greater than 1 is better, which means more concurrent modules init): {} \".format(((total_module_time / duration)).round(4)))\n",
    "    \n",
    "    return start_min, finish_max, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def get_color_list(df: pd.DataFrame, notification_color: str = notification_color, default_color: str=module_color) -> list:\n",
    "    \"\"\"Utility to get color list for plotly\"\"\"\n",
    "    color_list = []\n",
    "    for i in range(len(df)):\n",
    "        if df.index[i].endswith(notif_suffix):\n",
    "            color_list.append(notification_color)\n",
    "        else:\n",
    "            color_list.append(default_color)\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def plot_module_time_chart(df: pd.DataFrame, small_set: int=-1, use_plt: bool=True, sort_by: str=\"start_time\", title: str='FunOS Module Init Duration', group_table: dict=None, simple_group_name: bool=True, cutoff_group_names: int=10, save_file_name: str =full_chart_file_name, disp_granualarity_ms: int=10, debug: bool=False) -> None:\n",
    "    \"\"\"Plot the module init time chart\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    small_set : int, optional\n",
    "        number of rows to plot, by default -1 (plot all)\n",
    "    sort_by : str, optional\n",
    "        sort by column, by default \"start_time\"\n",
    "    title : str, optional\n",
    "        title of the chart, by default 'FunOS Module Init Duration'\n",
    "    group_table : dict, optional\n",
    "        group table, by default None, if not None, group the modules based on the group_table\n",
    "    simple_group_name : bool, optional\n",
    "        use simple group name, by default True\n",
    "    cutoff_group_names : int, optional\n",
    "        cutoff group names, by default 12, cut off text display for group names\n",
    "    disp_granualarity_ms: int, optional\n",
    "        X axis display granualarity, in ms time unit, by default 10\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # add max min for creating tick\n",
    "\n",
    "    df_use = df.copy()\n",
    "\n",
    "    X_disp_granualarity = disp_granualarity_ms\n",
    "    X_granualarity = 1000000\n",
    "    x_tick_str = \"ms\"\n",
    "    # if X_granualarity == 1000000:\n",
    "    #     x_tick_str = \"ms\"\n",
    "    # elif X_granualarity == 1000000000:\n",
    "    #     x_tick_str = \"s\"\n",
    "\n",
    "    df_use.sort_values(by=[sort_by], inplace=True, ascending=True)\n",
    "\n",
    "    if small_set > 0:\n",
    "        df_use = df_use[:small_set]\n",
    "\n",
    "    if save_file_name[-4:] != \".png\":\n",
    "        save_file_name = save_file_name + \".png\"\n",
    "    \n",
    "    start_min, finish_max, duration = get_start_finish_times(df_use, debug=debug)\n",
    "\n",
    "    x_ticks = np.arange(0, duration, X_disp_granualarity * X_granualarity)\n",
    "    x_tick_labels = [\"{} {}\".format(str(int(x)), x_tick_str) for x in x_ticks/X_granualarity]\n",
    "\n",
    "    figsize=(40, len(df_use))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"x_ticks: {}\".format(x_ticks[:10]))\n",
    "        print(\"x_tick_labels: {}\".format(x_tick_labels[:10]))\n",
    "        print(\"figsize: {}\".format(figsize))\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        display(df_use.head())\n",
    "        display(df_use.describe())\n",
    "\n",
    "    if use_plt:\n",
    "        color_list = get_color_list(df_use)\n",
    "        # fig, ax = plt.subplots(1, figsize=(40, 50))\n",
    "        fig, ax = plt.subplots(1, figsize=figsize)\n",
    "        p1 = ax.barh(df_use.index, width=df_use['module_init_duration'], left=df_use['start_time'], color=color_list)\n",
    "\n",
    "        ax.set(xlabel='ms', ylabel='Modules')\n",
    "\n",
    "        #Invert y axis\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        #customize x-ticks\n",
    "        plt.xticks(ticks=x_ticks, labels=x_tick_labels)\n",
    "\n",
    "        # title\n",
    "        if group_table:\n",
    "            title = \"{}: collapsed\".format(title)\n",
    "        plt.title(title, fontsize=20)\n",
    "\n",
    "        #rotate x-ticks\n",
    "        plt.xticks(rotation=60)\n",
    "        #add grid lines\n",
    "        plt.grid(axis='x', alpha=0.5)\n",
    "        plt.grid(axis='y', alpha=0.5)\n",
    "\n",
    "        if group_table:\n",
    "            if simple_group_name:\n",
    "                # testing simpler way\n",
    "                y_pos = np.arange(len(group_table))\n",
    "                y_label = [\"{} & {} modules\".format(v[0], len(v)) if len(v) > 1 else v[0] for k, v in group_table.items()]\n",
    "                ax.set_yticks(y_pos, labels=y_label)\n",
    "                pass\n",
    "            else:\n",
    "                x_base = 6000000\n",
    "                for i, (k, v) in enumerate(group_table.items()):\n",
    "                    # print(\"i: {}, k: {} ({}), v: {}\".format(i, k, len(v), v))\n",
    "                    if len(v) > cutoff_group_names:\n",
    "                        v_str = \"{}...(total: {})\".format(v[:cutoff_group_names], len(v))\n",
    "                    else:\n",
    "                        v_str = \"{}\".format(v)\n",
    "                    ax.text(x_base*(i+1), i, v_str, fontsize=21, color='red')\n",
    "                    # ax.text(20000000, 1, 'Unicode: Institut für Festkörperphysik')\n",
    "\n",
    "        #save fig\n",
    "        plt.savefig(save_file_name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        # use plotly\n",
    "        # plotly doesn't support 'left' argument, so need to create manualy bars\n",
    "        # https://community.plotly.com/t/broken-barh-plot/36496\n",
    "        # assert False, \"Ploty not supported yet\"\n",
    "\n",
    "        df_use.sort_values(by=[sort_by], inplace=True, ascending=False)\n",
    "\n",
    "        # fig = px.bar(df, x=\"module_init_duration\", y=df.index, orientation='h', height=1000)\n",
    "        \n",
    "\n",
    "        # fig = go.Figure(go.Bar(\n",
    "        #     x=df[\"module_init_duration\"],\n",
    "        #     y=df.index,\n",
    "        #     orientation='h'))\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=df_use.index,\n",
    "            x=df_use[\"start_time\"],\n",
    "            name='start',\n",
    "            orientation='h',\n",
    "            # width=20,\n",
    "            marker=dict(\n",
    "                color='rgba(256, 256, 256, 0.0)',\n",
    "                line=dict(color='rgba(256, 256, 256, 0.0)', width=1)\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        fig.add_trace(go.Bar(\n",
    "            y=df_use.index,\n",
    "            x=df_use[\"module_init_duration\"],\n",
    "            name='module init duration',\n",
    "            orientation='h',\n",
    "            # width=20,\n",
    "            marker=dict(\n",
    "                color='rgba(58, 71, 80, 0.6)',\n",
    "                line=dict(color='rgba(58, 71, 80, 1.0)', width=1)\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(barmode='stack')\n",
    "\n",
    "        # https://github.com/jupyter/nbconvert/issues/944\n",
    "        fig.show(renderer=\"notebook\")\n",
    "\n",
    "        # for static image to reduce the embedded image size\n",
    "        # from IPython.display import Image\n",
    "        # Image(fig.to_image())\n",
    "\n",
    "        # fig = px.timeline(df, x_start=\"start_time\", x_end=\"finish_time\", y=df_use.index, title=title)\n",
    "        # fig.update_yaxes(autorange=\"reversed\") # otherwise tasks are listed from the bottom up\n",
    "        # fig.show()\n",
    "\n",
    "    del df_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def dump_file(df: pd.DataFrame, file_name: str, sorted_key: str = None):\n",
    "    \"\"\"Dump the dataframe to a file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe to dump\n",
    "    file_name : str\n",
    "        file name to dump to\n",
    "    sorted_key : str, optional\n",
    "        key to sort the dataframe, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # save df to json file\n",
    "    sorted_df = df.copy()\n",
    "    if sorted_key:\n",
    "        sorted_df.sort_values(by=[sorted_key], inplace=True, ascending=True)\n",
    "    \n",
    "    txt_file_name = file_name + \".txt\"\n",
    "    with open(txt_file_name, \"w\") as f:\n",
    "        f.write(sorted_df.to_string())\n",
    "    sorted_df_file_name = file_name\n",
    "    json_file_name = sorted_df_file_name + \".json\"\n",
    "    sorted_df.to_json(json_file_name)\n",
    "    csv_file_name = sorted_df_file_name + \".csv\"\n",
    "    sorted_df.to_csv(csv_file_name)\n",
    "\n",
    "    yaml_file_name = sorted_df_file_name + \".yaml\"\n",
    "    with open(yaml_file_name, \"w\") as f:\n",
    "        yaml.dump({'result': json.loads(sorted_df.to_json(orient='records'))}, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def get_collapsed_df(df_in:pd.DataFrame, threshold: float, debug: bool = False) -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"Collpased df using the threshold\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    threshold : float\n",
    "        threshold value to collapse, fraction to the largest duration\n",
    "        ex> 0.10 means collapse all the modules with duration less than 10% of the largest duration\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        collapsed dataframe\n",
    "    dict\n",
    "        group table, key is the group name, value is the list of modules in the group\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_group_name(name):\n",
    "        \"\"\"form group name\"\"\"\n",
    "        if name.endswith(notif_suffix):\n",
    "            # for notification\n",
    "            group_name = \"group_{}{}\".format(n_event, notif_suffix)\n",
    "        else:\n",
    "            group_name = \"group_{}\".format(n_event)\n",
    "        return group_name\n",
    "\n",
    "    df = df_in.copy()\n",
    "    df.sort_values(by=['start_time'], inplace=True, ascending=True)\n",
    "\n",
    "    # df_collapsed['module_init_duration'] = df_collapsed['module_init_duration'].apply(lambda x: x if x > threshold else 0)\n",
    "    # df_collapsed = df_collapsed[df_collapsed['module_init_duration'] > 0]\n",
    "    new_events = []\n",
    "    n_event = 0\n",
    "    num_included = 0\n",
    "    cur_duration = 0 # current start to the finish of the last event\n",
    "    cur_start = 0\n",
    "    cur_finish = 0\n",
    "    last = len(df)\n",
    "    group_table = {}\n",
    "    for i in range(len(df)):\n",
    "        name, start, finish, duration = df.index[i], df.iloc[i].start_time, df.iloc[i].finish_time, df.iloc[i].module_init_duration\n",
    "        if debug:\n",
    "            print(name, start, finish, duration)\n",
    "\n",
    "        if cur_duration == 0:\n",
    "            num_included = 0\n",
    "            cur_duration = duration\n",
    "            cur_start = start\n",
    "            cur_finish = finish\n",
    "            group_modules = []\n",
    "        \n",
    "        cur_finish = max(cur_finish, finish)\n",
    "        cur_duration = cur_finish - cur_start\n",
    "        # print(\"cur_start, cur_finish, cur_duration: {}, {}\".format(cur_start, cur_finish, cur_duration))\n",
    "\n",
    "        # peek the next check if next module passes the thresholds\n",
    "        next_module_pass_threshold = False\n",
    "        if i < last - 1:\n",
    "            next_name, next_start, next_finish, next_duration = df.index[i+1], df.iloc[i+1].start_time, df.iloc[i+1].finish_time, df.iloc[i+1].module_init_duration\n",
    "            next_finish = max(cur_finish, next_finish)\n",
    "            # print(\"next_finish {}, next_finish - cur_start {}\".format(next_finish, next_finish - cur_start))\n",
    "            # if next duration is more than threshold and there is more than one collapsed, then stop collapsing the current modules\n",
    "            # if next_finish - cur_start > threshold and num_included > 0:\n",
    "            if next_finish - cur_start > threshold:\n",
    "                next_module_pass_threshold = True\n",
    "                group_modules.append(name)\n",
    "\n",
    "        \n",
    "        # if cur_duration + duration > threshold:\n",
    "        if cur_duration > threshold or next_module_pass_threshold:\n",
    "            # peek the next one and keep adding until the threshold is reached\n",
    "            # create a new one\n",
    "\n",
    "            # if name.endswith(notif_suffix):\n",
    "            #     group_name = \"group_{}{}\".format(n_event, notif_suffix)\n",
    "            # else:\n",
    "            #     group_name = \"group_{}\".format(n_event)\n",
    "            group_name = _get_group_name(name)\n",
    "            \n",
    "            new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "            if debug:\n",
    "                print(\"includes {}, added: {}\".format(num_included, new_d))\n",
    "            new_events.append(new_d)\n",
    "            cur_duration = 0\n",
    "            n_event += 1\n",
    "            group_table[group_name] = group_modules if num_included > 0 else [name]\n",
    "            # group_modules = []\n",
    "        else:\n",
    "            group_modules.append(name)\n",
    "            num_included += 1\n",
    "                \n",
    "    if cur_duration != 0:\n",
    "        # group_name = \"group_{}\".format(n_event)\n",
    "        group_name = _get_group_name(name)\n",
    "        new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "        if debug:\n",
    "            print(\"added: {}\".format(new_d))\n",
    "        new_events.append(new_d)\n",
    "        group_table[group_name] = group_modules\n",
    "\n",
    "    df_collapsed = pd.DataFrame(new_events)\n",
    "    df_collapsed.set_index('module_name', inplace=True)\n",
    "    df_collapsed.head()\n",
    "    \n",
    "    return df_collapsed, group_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX REMOVE\n",
    "def print_group_table(group_table: dict, threshold: float, save_file_name: str = None):\n",
    "    \"\"\"Print the group table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group_table : dict\n",
    "        group table, key is the group name, value is the list of modules in the group\n",
    "    threshold : float\n",
    "        threshold (nsec) value to collapse, fraction to the largest duration\n",
    "    save_file_name : str, optional\n",
    "        file to save the group table, by default None\n",
    "    \"\"\"\n",
    "    output  = \"Collapsed module group report (threshold time of {} ns):\\n\".format(threshold)\n",
    "    output += \"========================\\n\"\n",
    "    for key, value in group_table.items():\n",
    "        output += (\"{}({}): {}\\n\".format(key, len(value), value))\n",
    "        # print(\"{}({}): {}\".format(key, len(value), value))\n",
    "\n",
    "    print(output)\n",
    "\n",
    "    if save_file_name:\n",
    "        if save_file_name[:-4] != \".txt\":\n",
    "            save_file_name += \".txt\"\n",
    "        with open(save_file_name, \"w\") as f:\n",
    "            f.write(output)\n",
    "    \n",
    "    # for k, v in group_table.items():\n",
    "    #     print(\"{}:\".format(k))\n",
    "    #     for m in v:\n",
    "    #         print(\"  {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files and convert it to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example input:\n",
    "```\n",
    "{\n",
    "    \"accel_telem-init\": [0.024845458, 0.024987833],\n",
    "    \"adi-init\": [0.040308791, 0.040344291],\n",
    "    \"app-init\": [0.029524875, 0.029535041],\n",
    "...\n",
    "```\n",
    "\n",
    "Example output:\n",
    "```\n",
    "\tmodule_name\tstart_time\tfinish_time\n",
    "0\taccel_telem-init\t0.024845\t0.024988\n",
    "1\tadi-init\t0.040309\t0.040344\n",
    "2\tapp-init\t0.029525\t0.029535\n",
    "3\tbin_ctl_handler-init\t0.002356\t0.002492\n",
    "4\tbm-init\t0.030727\t0.030735\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# load input data\n",
    "\n",
    "note_str = '### Checking data from `{}`'.format(modules_init_file_name)\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df = load_module_init_data(modules_init_file_name, convert_time_to_ns=True, debug=False)\n",
    "threshold_collapse = get_duration_threshold(fun_module_init_df, threshold=0.01)\n",
    "print(\"Threshold collapse: {}\".format(threshold_collapse))\n",
    "fun_module_init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# load notification input data\n",
    "\n",
    "note_str = '### Checking data from `{}`'.format(notificaiotns_init_file_name)\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_notification_init_df = load_notification_init_data(notificaiotns_init_file_name, convert_time_to_ns=True, dummy_duration = 2*threshold_collapse/1e9, debug=False)\n",
    "fun_notification_init_df.head(20)\n",
    "# len(fun_notification_init_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# concat\n",
    "fun_module_notif_init_df = pd.concat([fun_module_init_df, fun_notification_init_df])\n",
    "# fun_module_notif_init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "note_str = '### Summary statistics: (time in ns)'\n",
    "\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "note_str = \"Total number of modules: {}\".format(len(fun_module_init_df))\n",
    "display(Markdown(note_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all module init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# plot the events\n",
    "plot_module_time_chart(fun_module_init_df, disp_granualarity_ms=1000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# plot the events\n",
    "plot_module_time_chart(fun_module_notif_init_df, save_file_name=full_module_notif_chart, disp_granualarity_ms=1000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    fun_module_init_df.loc[['forwarding-init', 'network_unit-init', 'ethernet-init']]\n",
    "    # fun_module_init_df.index\n",
    "    # fun_module_init_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "\n",
    "# sorted_df_file_name = \"fun_module_init_df_sorted\"\n",
    "dump_file(fun_module_init_df, sorted_df_file_name, \"start_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapsing short activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# threshold = get_duration_threshold(fun_module_init_df, threshold=0.01)\n",
    "note_str = \"Collapse module init time lower than threshold ({} ns)\".format(_fmt(int(threshold_collapse), True))\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df_collapsed, group_table = get_collapsed_df(fun_module_init_df, threshold_collapse, debug=False)\n",
    "save_file_name = collapsed_chart_file_name\n",
    "plot_module_time_chart(fun_module_init_df_collapsed, disp_granualarity_ms=1000, debug=False, group_table=group_table, save_file_name=save_file_name)\n",
    "\n",
    "print_group_table(group_table, threshold=threshold_collapse, save_file_name=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# threshold_module_notif = get_duration_threshold(fun_module_notif_init_df, threshold=0.01)\n",
    "note_str = \"Collapse module init time lower than threshold ({} ns)\".format(_fmt(int(threshold_collapse), True))\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_notif_init_df_collapsed, group_table_module_notif = get_collapsed_df(fun_module_notif_init_df, threshold_collapse, debug=False)\n",
    "\n",
    "save_file_name = collapsed_chart_module_notif_file_name \n",
    "\n",
    "plot_module_time_chart(fun_module_notif_init_df_collapsed, disp_granualarity_ms=1000, debug=False, group_table=group_table_module_notif, save_file_name=save_file_name)\n",
    "\n",
    "print_group_table(group_table_module_notif, threshold=threshold_collapse, save_file_name=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "plot_module_time_chart(fun_module_init_df, use_plt=False, disp_granualarity_ms=1000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "plot_module_time_chart(fun_module_notif_init_df, use_plt=False, disp_granualarity_ms=1000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "plot_module_time_chart(fun_module_init_df_collapsed, use_plt=False, disp_granualarity_ms=1000, debug=False, group_table=group_table, save_file_name=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "plot_module_time_chart(fun_module_notif_init_df_collapsed, use_plt=False, disp_granualarity_ms=1000, debug=False, group_table=group_table, save_file_name=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop here, the following is testing code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://community.plotly.com/t/broken-barh-plot/36496/2\n",
    "\n",
    "def broken_bars(xstart, xwidth, ystart, yh, colors):\n",
    "    #xstart - list of x-start coord for each bar\n",
    "    #xwidth = list of bar widths\n",
    "    #ystart - number y-start coord for each bar\n",
    "    #yh - number- height of eah bar\n",
    "    #colors = list of bar colors\n",
    "    \n",
    "    if len(xstart) != len(xwidth) or  len(xstart) != len(colors):\n",
    "        raise ValueError('xstart, xwidth and colors must have the same length')\n",
    "    shapes = []    \n",
    "    for k in range(len(xstart)):\n",
    "        shapes.append(dict(type=\"rect\",\n",
    "                           x0=xstart[k],\n",
    "                           y0=ystart,\n",
    "                           x1=xstart[k] + xwidth[k],\n",
    "                           y1=ystart+yh,\n",
    "                           fillcolor=colors[k],\n",
    "                           line_color=colors[k]))\n",
    "    return shapes    \n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(width=600, height=500,\n",
    "                  xaxis_range = [0, 150],\n",
    "                  yaxis_range = [0, 40],\n",
    "                  shapes=broken_bars([10, 100, 130 ], [50, 20, 10], 20, 9, \n",
    "                                     colors=['orange', 'green', 'red' ]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broken_bars2(xstart, xwidth, ystart, yh, colors):\n",
    "    #the same tests as above\n",
    "    data =[]\n",
    "    for k in range(len(xstart)):\n",
    "        data.append(go.Scatter(x = [xstart[k], xstart[k]+xwidth[k],xstart[k]+xwidth[k], xstart[k]],\n",
    "                               y = [ystart]*2+[ystart+yh]*2, fill='toself', fillcolor=colors[k], mode='lines',\n",
    "                               line_color=colors[k], name=f'bar{k}'))\n",
    "                    \n",
    "    return data\n",
    "fig = go.Figure(data= broken_bars2([10, 100, 130 ], [50, 20, 10], 20, 9, \n",
    "                                     colors=['orange', 'green', 'red' ]))\n",
    "fig.update_layout(width=600, height=500,\n",
    "                  xaxis_range = [0, 150],\n",
    "                  yaxis_range = [0, 40]);\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to json file\n",
    "sorted_df = fun_module_init_df.copy()\n",
    "sorted_df.sort_values(by=['start_time'], inplace=True, ascending=True)\n",
    "sorted_df_file_name = \"fun_module_init_df_sorted\"\n",
    "json_file_name = sorted_df_file_name + \".json\"\n",
    "sorted_df.to_json(json_file_name)\n",
    "csv_file_name = sorted_df_file_name + \".csv\"\n",
    "sorted_df.to_csv(csv_file_name)\n",
    "\n",
    "yaml_file_name = sorted_df_file_name + \".yaml\"\n",
    "with open(yaml_file_name, \"w\") as f:\n",
    "    yaml.dump({'result': json.loads(sorted_df.to_json(orient='records'))}, f, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do sanity check\n",
    "print(\"len of fun_module_init_df: {}\".format(len(fun_module_init_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in group_table.items():\n",
    "    count += len(v)\n",
    "print(\"len of group_table: {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = fun_module_init_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values(by=['start_time'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(30).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[['funvisor-init']].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.round().tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = fun_module_init_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.sort_values(by=['start_time'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = small_df[:42]\n",
    "t = small_df\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(t, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = []\n",
    "n_event = 0\n",
    "num_included = 0\n",
    "cur_duration = 0 # current start to the finish of the last event\n",
    "cur_start = 0\n",
    "cur_finish = 0\n",
    "last = len(t)\n",
    "group_table = {}\n",
    "for i in range(len(t)):\n",
    "    name, start, finish, duration = t.index[i], t.iloc[i].start_time, t.iloc[i].finish_time, t.iloc[i].module_init_duration\n",
    "    print(name, start, finish, duration)\n",
    "\n",
    "    if cur_duration == 0:\n",
    "        num_included = 0\n",
    "        cur_duration = duration\n",
    "        cur_start = start\n",
    "        cur_finish = finish\n",
    "        group_modules = [name]\n",
    "    \n",
    "    cur_finish = max(cur_finish, finish)\n",
    "    cur_duration = cur_finish - cur_start\n",
    "    # print(\"cur_start, cur_finish, cur_duration: {}, {}\".format(cur_start, cur_finish, cur_duration))\n",
    "\n",
    "    # peek the next check if next module passes the thresholds\n",
    "    next_module_pass_threshold = False\n",
    "    if i < last - 1:\n",
    "        next_name, next_start, next_finish, next_duration = t.index[i+1], t.iloc[i+1].start_time, t.iloc[i+1].finish_time, t.iloc[i+1].module_init_duration\n",
    "        next_finish = max(cur_finish, next_finish)\n",
    "        # print(\"next_finish {}, next_finish - cur_start {}\".format(next_finish, next_finish - cur_start))\n",
    "        # if next duration is more than threshold and there is more than one collapsed, then stop collapsing the current modules\n",
    "        if next_finish - cur_start > threshold and num_included > 0:\n",
    "            next_module_pass_threshold = True\n",
    "    \n",
    "    # if cur_duration + duration > threshold:\n",
    "    if cur_duration > threshold or next_module_pass_threshold:\n",
    "        # peek the next one and keep adding until the threshold is reached\n",
    "        # create a new onew\n",
    "        group_name = \"group_{}\".format(n_event)\n",
    "        new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "        print(\"includes {}, added: {}\".format(num_included, new_d))\n",
    "        new_events.append(new_d)\n",
    "        cur_duration = 0\n",
    "        n_event += 1\n",
    "        group_table[group_name] = group_modules if num_included > 0 else [name]\n",
    "        group_modules = []\n",
    "    else:\n",
    "        group_modules.append(name)\n",
    "        num_included += 1\n",
    "        pass\n",
    "            \n",
    "if cur_duration != 0:\n",
    "    group_name = \"group_{}\".format(n_event)\n",
    "    new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "    print(\"added: {}\".format(new_d))\n",
    "    new_events.append(new_d)\n",
    "    group_table[group_name] = group_modules\n",
    "\n",
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str = group_table['group_6']\n",
    "t_str1 = ','.join(t_str)\n",
    "t_str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table_str = []\n",
    "for k, v in group_table.items():\n",
    "    dict = {}\n",
    "    dict[\"group_name\"] = k\n",
    "    dict[\"modules\"] = ','.join(v)\n",
    "    group_table_str.append(dict)\n",
    "\n",
    "# display(group_table_str)\n",
    "for d in group_table_str:\n",
    "    print(\"{}: {}\".format(d[\"group_name\"], d[\"modules\"]))\n",
    "\n",
    "for k, v in group_table.items():\n",
    "    print(\"{}:\".format(k))\n",
    "    for m in v:\n",
    "        print(\"  {}\".format(m))\n",
    "    # print(\"{}: {}\".format(d[\"group_name\"], d[\"modules\"]))\n",
    "\n",
    "# group_table_str_df = pd.DataFrame(group_table_str)\n",
    "# group_table_str_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(group_table)\n",
    "# group_table_df = pd.DataFrame.from_dict(group_table, orient='index')\n",
    "# display(group_table_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_events)\n",
    "new_df.set_index('module_name', inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(new_df, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15228333.0 - 15216708.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15257625.0-15228333.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(t1, small_set=-1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = small_df[-42:]\n",
    "display(t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa8f9c45b60853bb3d615f814548b5337da45fc6ea40b493b018f80b808d764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
