{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fun_alloc_forever experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *NOTE*: run this command to clean output cell and meta data.\n",
    "# $ nb-clean clean ./measure_malloc_stat.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate html\n",
    "# $ python ./convert_nb.py --filename ./measure_malloc_stat.ipynb --execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# title print\n",
    "# more descriptions\n",
    "# move to package modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from typing import Iterable, Any, List, Optional, Union, Callable, TextIO, Dict, Tuple\n",
    "\n",
    "from utils import *\n",
    "from utils_fod import *\n",
    "from utils_plot import *\n",
    "from convert_nb import generate_report\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "#https://stackoverflow.com/questions/36288670/how-to-programmatically-generate-markdown-output-in-jupyter-notebooks\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "pd.set_option('max_colwidth', 800)\n",
    "\n",
    "def printmd(string):  ###\n",
    "    display(Markdown(string))  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_MALLOC_FOREVER_STAT = True\n",
    "SHOW_HU_INIT_STAT = False\n",
    "GENERATE_HTML = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# measurement of malloc time over 160 vps\n",
    "# CONFIG_FILE = \"configs/measure_malloc_stat_cluster_wp2_160vps.yml\"\n",
    "\n",
    "# measurement of spinlock wait time with benchmark and cluster wp 160 vps\n",
    "CONFIG_FILE = \"configs/measure_malloc_stat_cluster_spinlock_wait_160vp.yml\"\n",
    "\n",
    "# measurement of spinlock wait time with benchmark and cluster wp\n",
    "# CONFIG_FILE = \"configs/measure_malloc_stat_cluster_spinlock_wait.yml\"\n",
    "\n",
    "# measurement using cluster wp over more number VPs\n",
    "# CONFIG_FILE = \"configs/measure_malloc_stat_cluster_wp2.yml\"\n",
    "\n",
    "# measurement using cluster wp\n",
    "# CONFIG_FILE = \"configs/measure_malloc_stat_cluster_wp.yml\"\n",
    "\n",
    "# initial measurement\n",
    "# CONFIG_FILE = \"configs/measure_malloc_stat.yml\"\n",
    "\n",
    "# WDT_LONG_MSG = \"WDT: Long-running WU warning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_str = \"Config file: {}\".format(CONFIG_FILE)\n",
    "printmd(note_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(CONFIG_FILE)\n",
    "\n",
    "format_patch = config[\"format_patch\"] if \"format_patch\" in config else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_str = \"Here are the fod job links used for testing. \"\n",
    "printmd(note_str)\n",
    "\n",
    "collected_jobs = fod_extract_pages(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(collected_jobs: List[Dict[str, Any]], pattern: str, patch: bool=False, plot_summary: bool=True, plot_hist: bool=True, skip_summary_state: bool=False) -> List[pd.DataFrame]:\n",
    "    dfs = []\n",
    "    for job in collected_jobs:\n",
    "        console_response = job[\"console_response\"]\n",
    "        filtered_lines = fod_extract_lines_with_pattern_from_console(\n",
    "            console_response, pattern\n",
    "        )\n",
    "        extracted_json = fod_extract_json_from_line(filtered_lines, patch=patch)\n",
    "        df = pd.DataFrame(extracted_json)\n",
    "        dfs.append(df)\n",
    "        if not skip_summary_state:\n",
    "            print(\"job_no: {}\".format(job[\"job_no\"]))\n",
    "            print(\"len of df: {}\".format(len(df)))\n",
    "            display(df)\n",
    "        if plot_summary:\n",
    "            df.plot(kind=\"bar\", figsize=(20, 10), fontsize=10)\n",
    "            plt.show()\n",
    "        if plot_hist:\n",
    "            bins = 40\n",
    "\n",
    "            title = \"Histogram of avg of job {}\".format(job[\"job_no\"])\n",
    "            plot_histogram(df, \"avg\", title, \"usec\", \"count\", bins=bins)\n",
    "\n",
    "            title = \"Histogram of min of job {}\".format(job[\"job_no\"])\n",
    "            plot_histogram(df, \"min\", title, \"usec\", \"count\", bins=bins)\n",
    "\n",
    "            title = \"Histogram of max of job {}\".format(job[\"job_no\"])\n",
    "            plot_histogram(df, \"max\", title, \"usec\", \"count\", bins=bins)\n",
    "\n",
    "            title = \"Histogram of max of job {}\".format(job[\"job_no\"])\n",
    "            plot_histogram(df, \"dev\", title, \"usec\", \"count\", bins=bins)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate different pattern\n",
    "\n",
    "def show_all_runs(npars: List[int], col_titles: List[str]):\n",
    "    all_dfs = []\n",
    "    for npar in npars:\n",
    "\n",
    "        search_pattern_format = config[\"search_pattern\"] if \"search_pattern\" in config else \"TEST_2,nparallel {},\" \n",
    "        if \"{}\" in search_pattern_format:\n",
    "            search_pattern = search_pattern_format.format(npar)\n",
    "        else:\n",
    "            search_pattern = search_pattern_format\n",
    "        \n",
    "        title_default = \"Histogram of malloc_forever (2 kB) **durations** with {} parallel vp(s)\".format(npar)\n",
    "\n",
    "        title = config['title'] if 'title' in config else title_default\n",
    "        title = title.format(npar)\n",
    "\n",
    "        printmd(\"### \" + title + \"\\n\\n\")\n",
    "\n",
    "        dfs = generate_summary(collected_jobs, search_pattern, patch=True, plot_summary=False, plot_hist=False, skip_summary_state=False)\n",
    "\n",
    "        bins = config[\"bins\"] if \"bins\" in config else 20\n",
    "        xlabel = config[\"xlabel\"] if \"xlabel\" in config else \"usec\"\n",
    "        plot_2_subplot(dfs, title, xlabel, col_titles, ylim=(npar//2 + int(npar * 0.15)), bins=bins)\n",
    "        all_dfs.append(dfs)\n",
    "    return all_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scale_per_num_vp(all_dfs, single_plots, top_title, ylabel):\n",
    "    cols = [\"avg\"]\n",
    "    # cols = [\"avg\", \"min\", \"max\", \"dev\"]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    fig.suptitle(top_title)\n",
    "    ymax = 0\n",
    "    for single_plot in single_plots:\n",
    "        avgs = []\n",
    "        for i in range(len(all_dfs)):\n",
    "            df = all_dfs[i][single_plot]\n",
    "            avgs.append(df[\"avg\"].values[0])\n",
    "\n",
    "        ymax = max(max(avgs), ymax)\n",
    "        axes[single_plot].scatter(npars, avgs)\n",
    "        xlabel = \"number of parallel VPs ({})\".format(col_titles[single_plot])\n",
    "        axes[single_plot].set(xlabel=xlabel, ylabel=ylabel)\n",
    "    \n",
    "    for single_plot in single_plots:\n",
    "        axes[single_plot].set_ylim(0, ymax*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_MALLOC_FOREVER_STAT:\n",
    "    note_str = \"## Experimental results\"\n",
    "    printmd(note_str)\n",
    "\n",
    "    note_str = \"Histogram is based on the performance metrics measured by each VPs for fun_alloc_forever(). Raw metric is measured using [perf_metric_record_uint64()](https://github.com/fungible-inc/FunOS/blob/0956197d6f3d96b1ba8ed08f997ed702467e8251/utils/common/perf_metric.c#L96) runs per each VPs.\"\n",
    "    printmd(note_str)\n",
    "\n",
    "    note_str = \"Note: we did not apply x axis limit for when the max x values is too large to make it hard to read small x values.\"\n",
    "    printmd(note_str)\n",
    "\n",
    "    note_str = \"\\n\\n\"\n",
    "    printmd(note_str)\n",
    "\n",
    "    # npars = [1, 18, 54, 90, 144, 180]\n",
    "    npars = config[\"npars\"] if \"npars\" in config else [1, 18, 54, 90, 144, 180]\n",
    "    # print(\"npars: {}\".format(npars))\n",
    "    col_titles = config[\"col_titles\"] if \"col_titles\" in config else [\"baseline\", \"skip unlock\"]\n",
    "    all_dfs = show_all_runs(npars, col_titles)\n",
    "    # assume all runs have same number runs\n",
    "    malloc_count = all_dfs[0][0][\"count\"].values[0]\n",
    "\n",
    "    note_str = \"Number of test done for each VP: {}\".format(malloc_count)\n",
    "    printmd(note_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"single_plots\" in config:\n",
    "    single_plots = config[\"single_plots\"]\n",
    "    # top_title = \"Performance of malloc_forever() with different number of parallel VPs\"\n",
    "    top_title = config[\"single_plots_top_title\"] if \"single_plots_top_title\" in config else \"Performance of malloc_forever() with different number of parallel VPs\"\n",
    "    ylabel = config[\"single_plots_ylabel\"] if \"single_plots_ylabel\" in config else \"alloc_forever() run time avg (usec)\"\n",
    "    plot_scale_per_num_vp(all_dfs, single_plots, top_title, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise SystemExit(\"Stop here, the following is testing code\")\n",
    "# STOP HERE\n",
    "# bellow is testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_line = fod_extract_lines_with_pattern_from_console(console_response, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = fod_extract_json_from_line(filtered_line, patch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict to dataframe\n",
    "df = pd.DataFrame(d)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Histogram of min of job {}\".format(collected_jobs[0][\"job_no\"])\n",
    "plot_histogram(df, \"min\", title, \"usec\", \"count\", bins=20)\n",
    "\n",
    "title = \"Histogram of avg of job {}\".format(collected_jobs[0][\"job_no\"])\n",
    "plot_histogram(df, \"avg\", title, \"usec\", \"count\", bins=20)\n",
    "\n",
    "title = \"Histogram of max of job {}\".format(collected_jobs[0][\"job_no\"])\n",
    "plot_histogram(df, \"max\", title, \"usec\", \"count\", bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.search('{(.+?)}', filtered_lines[0])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_str = \"{\"+ m.group(1)+\"}\"\n",
    "j_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace substring in string\n",
    "j_str = j_str.replace('\"usecs\" \"count\"', '\"usecs\",\"count\"')\n",
    "j_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json string to dict\n",
    "j = json.loads(j_str)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa8f9c45b60853bb3d615f814548b5337da45fc6ea40b493b018f80b808d764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
