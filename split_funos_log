#!/usr/bin/env python3

"""
This script tries to help a consumer of a FunOS log understand it better. It
provides options to split a single FunOS log into multiple files. The currently
supported keys to split on are ccv, resource type, flow ID, and flow faddr. By
default it will split on ccv.

Given an input logfile, the script will create a directory of files given by
the argument --directory. If this argument is not provided, then the default
behavior is to create a folder in the current directory with the logfile name
as the prefix and -processed as the suffix.

This is very useful for seeing the logs serialized in terms of a flow or a
specific VP.

There is also an option specific to FunTCP, --rtf, that reorders TCP fast trace
buffer output so that both the data and control fast trace buffer are in
sequential order. This only affects runs where FunTCP dumps the fast trace
buffer which is usually in case of aborts.
"""

import argparse
import pathlib
import enum
import re
import os


def create_directory(filename, directory):
    if not directory:
        cwd = os.getcwd()
        directory = os.path.join(cwd, filename + "-processed")

    pathlib.Path(directory).mkdir(parents=True, exist_ok=True)

    return directory


class Splitter:
    class State:
        def __init__(self, f):
            self.f = f

            self.ftr_buffer = []
            self.tracing = False

        def trace_buffer_start(self, timestamp, line):
            self.ftr_buffer.append((timestamp, line))
            self.tracing = True

        def trace_buffer_flush(self):
            if not self.ftr_buffer:
                return

            self.ftr_buffer.sort(key=lambda x: x[0])
            for _, line in self.ftr_buffer:
                self.f.write(line)

            self.tracing = False
            self.ftr_buffer = []

        def close(self):
            self.f.close()

    class Selector(enum.Enum):
        ccv = 0
        res_type = 1
        flow_id = 2
        flow_faddr = 3

    extractors = {
        Selector.ccv: r"^\[\d+\.\d+ (.*?)\]",
        Selector.res_type: r"flow\[.*?:(.*?):",
        Selector.flow_id: r"flow.*?\:.*?\:.*?\/(.*?)\/",
        Selector.flow_faddr: r"flow.*FA(\d+:\d+:\d+)",
    }

    ftr_timestamp_re = r"^.*ftr - tcp.*, ts (\d+)"
    unsorted_key = "unsorted"

    def __init__(self, directory, selector, rtf):
        self.directory = directory
        self.matcher = re.compile(self.extractors[selector])
        self.mappings = {}

        self.rtf = rtf
        self.ftr_timestamp_matcher = re.compile(self.ftr_timestamp_re)

    def mapping_create(self, key):
        f = open(os.path.join(self.directory, key), "w")
        state = Splitter.State(f)
        self.mappings[key] = state

        return state

    def mapping_get(self, key):
        state = self.mappings.get(key, None)
        if state is None:
            state = self.mapping_create(key)

        return state

    def reorder_rtf(self, state, line):
        match = self.ftr_timestamp_matcher.match(line)
        if not match:
            if state.tracing:
                state.trace_buffer_flush()

            return False

        timestamp = int(match.group(1))
        state.trace_buffer_start(timestamp, line)

        return True

    def process_line(self, line):
        match = self.matcher.search(line)
        key = match.group(1) if match else self.unsorted_key
        state = self.mapping_get(key)

        if self.rtf and key != self.unsorted_key:
            if self.reorder_rtf(state, line):
                return

        state.f.write(line)

    def close(self):
        for _, state in self.mappings.items():
            state.trace_buffer_flush()
            state.close()

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()


def handle_args():
    description = "A script to split FunOS logs"

    parser = argparse.ArgumentParser(description=description)
    parser.add_argument("log", help="Logfile filename")
    parser.add_argument(
        "--by",
        help="What to split by",
        choices=["ccv", "res_type", "flow_id", "flow_faddr"],
        default="ccv",
    )
    parser.add_argument(
        "--directory", help="Out directory for processed files", default=None
    )
    parser.add_argument(
        "--rtf", help="Reorder TCP fast trace buffer", action="store_true"
    )
    args = parser.parse_args()

    return args


if __name__ == "__main__":
    args = handle_args()
    directory = create_directory(args.log, args.directory)

    with open(args.log, "rb") as logfile:
        text = logfile.read().decode(errors="replace")

        with Splitter(directory, Splitter.Selector[args.by], args.rtf) as s:
            for line in text.split("\n"):
                s.process_line(line + "\n")
