{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FunOS module initialization analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyze module initilzation, durations and dependencies.\n",
    "Input file is `modules.json`.\n",
    "\n",
    "**References** for the notebook:\n",
    "- [Using simple barh based implementation](https://towardsdatascience.com/gantt-charts-with-pythons-matplotlib-395b7af72d72)\n",
    "- [Barh based with hints on how to make better representation](https://medium.com/geekculture/generate-gantt-chart-in-python-9d1e1fe9103e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- check plotly one more time (just use line chart ?) or use gannt style, which requre datetime conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *NOTE*: run this command to clean output cell and meta data.\n",
    "\n",
    "#nb-clean clean  ./funos_stats_analysis/fun_module_init_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "#https://stackoverflow.com/questions/36288670/how-to-programmatically-generate-markdown-output-in-jupyter-notebooks\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fmt(s, show_d=True):\n",
    "    \"\"\"show decimal number with comma\"\"\"\n",
    "    if show_d:\n",
    "        return format(s, \",d\")\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_of_dicts(raw_data: dict, convert_time_to_ns: bool, debug: bool) -> list:\n",
    "    \"\"\"convert the raw data (dict based format) to list of dicts\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_data : dict\n",
    "        raw data in dict format, module_name: [start_time, end_time]\n",
    "    \n",
    "    convert_time_to_ns : bool, optional\n",
    "        convert time to ns, by default True\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fun_module_init_list : list\n",
    "        list of dicts, each dict is a module, with keys: module_name, start_time, finish_time\n",
    "    \"\"\"\n",
    "    time_unit = 0\n",
    "    if convert_time_to_ns:\n",
    "        time_unit = 1000000000\n",
    "    fun_module_init_list = []\n",
    "    for module_name, module_data in raw_data.items():\n",
    "        temp_dict = {}\n",
    "        temp_dict['module_name'] = module_name\n",
    "        temp_dict['start_time'] = time_unit * float(module_data[0])\n",
    "        temp_dict['finish_time'] = time_unit * float(module_data[1])\n",
    "        # add duration column\n",
    "        temp_dict['module_init_duration'] = temp_dict['finish_time'] - temp_dict['start_time']\n",
    "        fun_module_init_list.append(temp_dict)\n",
    "\n",
    "    if debug:\n",
    "        print(\"List created\")\n",
    "        print(fun_module_init_list[:2])\n",
    "        print(\"Time conversion unit: {}\".format(time_unit))\n",
    "        # convert list of dicts to pandas dataframe\n",
    "        # fun_module_init_df = pd.DataFrame(fun_module_init_list)\n",
    "        # fun_module_init_df.head()\n",
    "    \n",
    "    return fun_module_init_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_data(input_file: str, convert_time_to_ns: bool = True, debug: bool=False) -> pd.DataFrame:\n",
    "    \"\"\"load input data from json file and convert to pandas dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        input file name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    fun_module_init_df : pd.DataFrame\n",
    "        pandas dataframe with module_name, start_time, finish_time, module_init_duration\n",
    "\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as f:\n",
    "        fun_module_init = json.load(f)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Number of modules: {}\".format(len(fun_module_init)))\n",
    "        print(\"fun_module_init.keys: {}\".format(fun_module_init.keys()))\n",
    "        print(\"fun_module_init['accel_telem-init']: {}\".format(fun_module_init['accel_telem-init']))\n",
    "\n",
    "    # convert to list of dicts\n",
    "    fun_module_init_list = convert_to_list_of_dicts(fun_module_init, convert_time_to_ns=convert_time_to_ns, debug=debug)\n",
    "\n",
    "    # convert to df\n",
    "    fun_module_init_df = pd.DataFrame(fun_module_init_list)\n",
    "    fun_module_init_df.set_index('module_name', inplace=True)\n",
    "\n",
    "    return fun_module_init_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `modules.json` file and convert it to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example input:\n",
    "```\n",
    "{\n",
    "    \"accel_telem-init\": [0.024845458, 0.024987833],\n",
    "    \"adi-init\": [0.040308791, 0.040344291],\n",
    "    \"app-init\": [0.029524875, 0.029535041],\n",
    "...\n",
    "```\n",
    "\n",
    "Example output:\n",
    "```\n",
    "\tmodule_name\tstart_time\tfinish_time\n",
    "0\taccel_telem-init\t0.024845\t0.024988\n",
    "1\tadi-init\t0.040309\t0.040344\n",
    "2\tapp-init\t0.029525\t0.029535\n",
    "3\tbin_ctl_handler-init\t0.002356\t0.002492\n",
    "4\tbm-init\t0.030727\t0.030735\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config, TODO use config file\n",
    "\n",
    "#INPUT_FILE = \"modules_posix.json\"\n",
    "INPUT_FILE = \"modules.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# load input data\n",
    "\n",
    "note_str = '### Checking data form `modules.json`'\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df = load_input_data(INPUT_FILE, convert_time_to_ns=True, debug=False)\n",
    "fun_module_init_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_str = '### Summary: time in ns'\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_str = \"Total number of modules: {}\".format(len(fun_module_init_df))\n",
    "display(Markdown(note_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all module init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_finish_times(df: pd.DataFrame, debug: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Utility to get start and finish times from df\"\"\"\n",
    "\n",
    "    start_min = df['start_time'].min() # first module start time\n",
    "    finish_max = df['finish_time'].max() # last module finish time\n",
    "    duration = finish_max - start_min # time between the first module start time and last module finish time\n",
    "\n",
    "    if debug:\n",
    "        print(\"start_min (start time of the first module): {}\".format(start_min))\n",
    "        print(\"finish_max: (finish time of the last module) {}\".format(finish_max))\n",
    "        # print(\"duration: (finish_max - start_min) {}\".format(finish_max - start_min))\n",
    "        # summary\n",
    "        total_module_time = df['module_init_duration'].sum()\n",
    "        print(\"Total module init time: {} ns\".format(total_module_time))\n",
    "        print(\"duration (time between the first module start time and last module finish time): {} ns\".format(finish_max - start_min))\n",
    "        print(\"'Total module init time' / 'duration' (greater than 1 is better, which means more concurrent modules init): {} \".format(((total_module_time / duration)).round(4)))\n",
    "    \n",
    "    return start_min, finish_max, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_module_time_chart(df: pd.DataFrame, small_set: int=-1, use_plt: bool=True, sort_by: str=\"start_time\", title: str='FunOS Module Init Duration', group_table: dict=None, simple_group_name: bool=True, cutoff_group_names: int=10, save_file_name: str =\"fun_module_init_chart\", disp_granualarity_ms: int=10, debug: bool=False) -> None:\n",
    "    \"\"\"Plot the module init time chart\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    small_set : int, optional\n",
    "        number of rows to plot, by default -1 (plot all)\n",
    "    sort_by : str, optional\n",
    "        sort by column, by default \"start_time\"\n",
    "    title : str, optional\n",
    "        title of the chart, by default 'FunOS Module Init Duration'\n",
    "    group_table : dict, optional\n",
    "        group table, by default None, if not None, group the modules based on the group_table\n",
    "    simple_group_name : bool, optional\n",
    "        use simple group name, by default True\n",
    "    cutoff_group_names : int, optional\n",
    "        cutoff group names, by default 12, cut off text display for group names\n",
    "    disp_granualarity_ms: int, optional\n",
    "        X axis display granualarity, in ms time unit, by default 10\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # add max min for creating tick\n",
    "\n",
    "    df_use = df.copy()\n",
    "\n",
    "    X_disp_granualarity = disp_granualarity_ms\n",
    "    X_granualarity = 1000000\n",
    "    x_tick_str = \"ms\"\n",
    "    # if X_granualarity == 1000000:\n",
    "    #     x_tick_str = \"ms\"\n",
    "    # elif X_granualarity == 1000000000:\n",
    "    #     x_tick_str = \"s\"\n",
    "\n",
    "    df_use.sort_values(by=[sort_by], inplace=True, ascending=True)\n",
    "\n",
    "    if small_set > 0:\n",
    "        df_use = df_use[:small_set]\n",
    "\n",
    "    if save_file_name[-4:] != \".png\":\n",
    "        save_file_name = save_file_name + \".png\"\n",
    "    \n",
    "    start_min, finish_max, duration = get_start_finish_times(df_use, debug=debug)\n",
    "\n",
    "    x_ticks = np.arange(0, duration, X_disp_granualarity * X_granualarity)\n",
    "    x_tick_labels = [\"{} {}\".format(str(int(x)), x_tick_str) for x in x_ticks/X_granualarity]\n",
    "\n",
    "    figsize=(40, len(df_use))\n",
    "    \n",
    "    if debug:\n",
    "        print(\"x_ticks: {}\".format(x_ticks[:10]))\n",
    "        print(\"x_tick_labels: {}\".format(x_tick_labels[:10]))\n",
    "        print(\"figsize: {}\".format(figsize))\n",
    "\n",
    "\n",
    "    if debug:\n",
    "        display(df_use.head())\n",
    "        display(df_use.describe())\n",
    "\n",
    "    if use_plt:\n",
    "        # fig, ax = plt.subplots(1, figsize=(40, 50))\n",
    "        fig, ax = plt.subplots(1, figsize=figsize)\n",
    "        p1 = ax.barh(df_use.index, width=df_use['module_init_duration'], left=df_use['start_time'])\n",
    "\n",
    "        ax.set(xlabel='ms', ylabel='Modules')\n",
    "\n",
    "        #Invert y axis\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        #customize x-ticks\n",
    "        plt.xticks(ticks=x_ticks, labels=x_tick_labels)\n",
    "\n",
    "        # title\n",
    "        if group_table:\n",
    "            title = \"{}: collapsed\".format(title)\n",
    "        plt.title(title, fontsize=20)\n",
    "\n",
    "        #rotate x-ticks\n",
    "        plt.xticks(rotation=60)\n",
    "        #add grid lines\n",
    "        plt.grid(axis='x', alpha=0.5)\n",
    "        plt.grid(axis='y', alpha=0.5)\n",
    "        # test\n",
    "\n",
    "        if group_table:\n",
    "            if simple_group_name:\n",
    "                # testing simpler way\n",
    "                y_pos = np.arange(len(group_table))\n",
    "                y_label = [\"{} & {} modules\".format(v[0], len(v)) if len(v) > 1 else v[0] for k, v in group_table.items()]\n",
    "                ax.set_yticks(y_pos, labels=y_label)\n",
    "                pass\n",
    "            else:\n",
    "                x_base = 6000000\n",
    "                for i, (k, v) in enumerate(group_table.items()):\n",
    "                    # print(\"i: {}, k: {} ({}), v: {}\".format(i, k, len(v), v))\n",
    "                    if len(v) > cutoff_group_names:\n",
    "                        v_str = \"{}...(total: {})\".format(v[:cutoff_group_names], len(v))\n",
    "                    else:\n",
    "                        v_str = \"{}\".format(v)\n",
    "                    ax.text(x_base*(i+1), i, v_str, fontsize=21, color='red')\n",
    "                    # ax.text(20000000, 1, 'Unicode: Institut für Festkörperphysik')\n",
    "\n",
    "        #save fig\n",
    "        plt.savefig(save_file_name)\n",
    "        plt.show()\n",
    "    else:\n",
    "        # use plotly\n",
    "        # plotly doesn't support 'left' argument, so need to create manualy bars\n",
    "        # https://community.plotly.com/t/broken-barh-plot/36496\n",
    "        assert False, \"Ploty not supported yet\"\n",
    "        # fig = px.timeline(df, x_start=\"start_time\", x_end=\"finish_time\", y=df_use.index, title=title)\n",
    "        # fig.update_yaxes(autorange=\"reversed\") # otherwise tasks are listed from the bottom up\n",
    "        # fig.show()\n",
    "\n",
    "    del df_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_file(df: pd.DataFrame, file_name: str, sorted_key: str = None):\n",
    "    \"\"\"Dump the dataframe to a file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe to dump\n",
    "    file_name : str\n",
    "        file name to dump to\n",
    "    sorted_key : str, optional\n",
    "        key to sort the dataframe, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # save df to json file\n",
    "    sorted_df = df.copy()\n",
    "    if sorted_key:\n",
    "        sorted_df.sort_values(by=[sorted_key], inplace=True, ascending=True)\n",
    "    \n",
    "    txt_file_name = file_name + \".txt\"\n",
    "    with open(txt_file_name, \"w\") as f:\n",
    "        f.write(sorted_df.to_string())\n",
    "    sorted_df_file_name = file_name\n",
    "    json_file_name = sorted_df_file_name + \".json\"\n",
    "    sorted_df.to_json(json_file_name)\n",
    "    csv_file_name = sorted_df_file_name + \".csv\"\n",
    "    sorted_df.to_csv(csv_file_name)\n",
    "\n",
    "    yaml_file_name = sorted_df_file_name + \".yaml\"\n",
    "    with open(yaml_file_name, \"w\") as f:\n",
    "        yaml.dump({'result': json.loads(sorted_df.to_json(orient='records'))}, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "# plot the events\n",
    "plot_module_time_chart(fun_module_init_df, disp_granualarity_ms=1000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    fun_module_init_df.loc[['forwarding-init', 'network_unit-init', 'ethernet-init']]\n",
    "    # fun_module_init_df.index\n",
    "    # fun_module_init_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "\n",
    "sorted_df_file_name = \"fun_module_init_df_sorted\"\n",
    "dump_file(fun_module_init_df, sorted_df_file_name, \"start_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collapsing short activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_threshold(df: pd.DataFrame, threshold: float=0.10) -> float:\n",
    "    \"\"\"Get the threshold value from the dataframe\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    threshold : float, optional\n",
    "        threshold value, by default 0.10\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        threshold value\n",
    "    \"\"\"\n",
    "    max_duration = df['module_init_duration'].max()\n",
    "\n",
    "    return float(int(max_duration * threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collapsed_df(df_in:pd.DataFrame, threshold: float, debug: bool = False) -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"Collpased df using the threshold\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe with module init data\n",
    "    threshold : float\n",
    "        threshold value to collapse, fraction to the largest duration\n",
    "        ex> 0.10 means collapse all the modules with duration less than 10% of the largest duration\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        collapsed dataframe\n",
    "    dict\n",
    "        group table, key is the group name, value is the list of modules in the group\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_in.copy()\n",
    "    df.sort_values(by=['start_time'], inplace=True, ascending=True)\n",
    "\n",
    "    # df_collapsed['module_init_duration'] = df_collapsed['module_init_duration'].apply(lambda x: x if x > threshold else 0)\n",
    "    # df_collapsed = df_collapsed[df_collapsed['module_init_duration'] > 0]\n",
    "    new_events = []\n",
    "    n_event = 0\n",
    "    num_included = 0\n",
    "    cur_duration = 0 # current start to the finish of the last event\n",
    "    cur_start = 0\n",
    "    cur_finish = 0\n",
    "    last = len(df)\n",
    "    group_table = {}\n",
    "    for i in range(len(df)):\n",
    "        name, start, finish, duration = df.index[i], df.iloc[i].start_time, df.iloc[i].finish_time, df.iloc[i].module_init_duration\n",
    "        if debug:\n",
    "            print(name, start, finish, duration)\n",
    "\n",
    "        if cur_duration == 0:\n",
    "            num_included = 0\n",
    "            cur_duration = duration\n",
    "            cur_start = start\n",
    "            cur_finish = finish\n",
    "            group_modules = []\n",
    "        \n",
    "        cur_finish = max(cur_finish, finish)\n",
    "        cur_duration = cur_finish - cur_start\n",
    "        # print(\"cur_start, cur_finish, cur_duration: {}, {}\".format(cur_start, cur_finish, cur_duration))\n",
    "\n",
    "        # peek the next check if next module passes the thresholds\n",
    "        next_module_pass_threshold = False\n",
    "        if i < last - 1:\n",
    "            next_name, next_start, next_finish, next_duration = df.index[i+1], df.iloc[i+1].start_time, df.iloc[i+1].finish_time, df.iloc[i+1].module_init_duration\n",
    "            next_finish = max(cur_finish, next_finish)\n",
    "            # print(\"next_finish {}, next_finish - cur_start {}\".format(next_finish, next_finish - cur_start))\n",
    "            # if next duration is more than threshold and there is more than one collapsed, then stop collapsing the current modules\n",
    "            # if next_finish - cur_start > threshold and num_included > 0:\n",
    "            if next_finish - cur_start > threshold:\n",
    "                next_module_pass_threshold = True\n",
    "                group_modules.append(name)\n",
    "\n",
    "        \n",
    "        # if cur_duration + duration > threshold:\n",
    "        if cur_duration > threshold or next_module_pass_threshold:\n",
    "            # peek the next one and keep adding until the threshold is reached\n",
    "            # create a new onew\n",
    "            group_name = \"group_{}\".format(n_event)\n",
    "            new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "            if debug:\n",
    "                print(\"includes {}, added: {}\".format(num_included, new_d))\n",
    "            new_events.append(new_d)\n",
    "            cur_duration = 0\n",
    "            n_event += 1\n",
    "            group_table[group_name] = group_modules if num_included > 0 else [name]\n",
    "            # group_modules = []\n",
    "        else:\n",
    "            group_modules.append(name)\n",
    "            num_included += 1\n",
    "                \n",
    "    if cur_duration != 0:\n",
    "        group_name = \"group_{}\".format(n_event)\n",
    "        new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "        if debug:\n",
    "            print(\"added: {}\".format(new_d))\n",
    "        new_events.append(new_d)\n",
    "        group_table[group_name] = group_modules\n",
    "\n",
    "    df_collapsed = pd.DataFrame(new_events)\n",
    "    df_collapsed.set_index('module_name', inplace=True)\n",
    "    df_collapsed.head()\n",
    "    \n",
    "    return df_collapsed, group_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_group_table(group_table: dict, threshold: float, save_file_name: str = None):\n",
    "    \"\"\"Print the group table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group_table : dict\n",
    "        group table, key is the group name, value is the list of modules in the group\n",
    "    threshold : float\n",
    "        threshold (nsec) value to collapse, fraction to the largest duration\n",
    "    save_file_name : str, optional\n",
    "        file to save the group table, by default None\n",
    "    \"\"\"\n",
    "    output  = \"Collapsed grput report (threshold time of {} ns):\\n\".format(threshold)\n",
    "    output += \"========================\\n\"\n",
    "    for key, value in group_table.items():\n",
    "        output += (\"{}({}): {}\\n\".format(key, len(value), value))\n",
    "        # print(\"{}({}): {}\".format(key, len(value), value))\n",
    "\n",
    "    print(output)\n",
    "\n",
    "    if save_file_name:\n",
    "        if save_file_name[:-4] != \".txt\":\n",
    "            save_file_name += \".txt\"\n",
    "        with open(save_file_name, \"w\") as f:\n",
    "            f.write(output)\n",
    "    \n",
    "    # for k, v in group_table.items():\n",
    "    #     print(\"{}:\".format(k))\n",
    "    #     for m in v:\n",
    "    #         print(\"  {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CALLS\n",
    "threshold = get_duration_threshold(fun_module_init_df, threshold=0.01)\n",
    "note_str = \"Collapse module init time lower than threshold ({} ns)\".format(_fmt(int(threshold), True))\n",
    "display(Markdown(note_str))\n",
    "\n",
    "fun_module_init_df_collapsed, group_table = get_collapsed_df(fun_module_init_df, threshold, debug=False)\n",
    "save_file_name = \"fun_module_init_df_collapsed\"\n",
    "plot_module_time_chart(fun_module_init_df_collapsed, disp_granualarity_ms=1000, debug=False, group_table=group_table, save_file_name=save_file_name)\n",
    "\n",
    "print_group_table(group_table, threshold=threshold, save_file_name=save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_file(df: pd.DataFrame, file_name: str, sorted_key: str = None):\n",
    "    \"\"\"Dump the dataframe to files (txt, json, csv, yaml)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        dataframe to dump\n",
    "    file_name : str\n",
    "        file name to dump to\n",
    "    sorted_key : str, optional\n",
    "        key to sort the dataframe, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # save df to json file\n",
    "    sorted_df = df.copy()\n",
    "    if sorted_key:\n",
    "        sorted_df.sort_values(by=[sorted_key], inplace=True, ascending=True)\n",
    "    \n",
    "    txt_file_name = file_name + \".txt\"\n",
    "    with open(txt_file_name, \"w\") as f:\n",
    "        f.write(sorted_df.to_string())\n",
    "    sorted_df_file_name = file_name\n",
    "    json_file_name = sorted_df_file_name + \".json\"\n",
    "    sorted_df.to_json(json_file_name)\n",
    "    csv_file_name = sorted_df_file_name + \".csv\"\n",
    "    sorted_df.to_csv(csv_file_name)\n",
    "\n",
    "    yaml_file_name = sorted_df_file_name + \".yaml\"\n",
    "    with open(yaml_file_name, \"w\") as f:\n",
    "        yaml.dump({'result': json.loads(sorted_df.to_json(orient='records'))}, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_file_name = \"fun_module_init_df_sorted\"\n",
    "dump_file(fun_module_init_df, sorted_df_file_name, \"start_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to json file\n",
    "sorted_df = fun_module_init_df.copy()\n",
    "sorted_df.sort_values(by=['start_time'], inplace=True, ascending=True)\n",
    "sorted_df_file_name = \"fun_module_init_df_sorted\"\n",
    "json_file_name = sorted_df_file_name + \".json\"\n",
    "sorted_df.to_json(json_file_name)\n",
    "csv_file_name = sorted_df_file_name + \".csv\"\n",
    "sorted_df.to_csv(csv_file_name)\n",
    "\n",
    "yaml_file_name = sorted_df_file_name + \".yaml\"\n",
    "with open(yaml_file_name, \"w\") as f:\n",
    "    yaml.dump({'result': json.loads(sorted_df.to_json(orient='records'))}, f, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do sanity check\n",
    "print(\"len of fun_module_init_df: {}\".format(len(fun_module_init_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k,v in group_table.items():\n",
    "    count += len(v)\n",
    "print(\"len of group_table: {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = fun_module_init_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.sort_values(by=['start_time'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(30).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[['funvisor-init']].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.round().tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = fun_module_init_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.sort_values(by=['start_time'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = small_df[:42]\n",
    "t = small_df\n",
    "display(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(t, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = []\n",
    "n_event = 0\n",
    "num_included = 0\n",
    "cur_duration = 0 # current start to the finish of the last event\n",
    "cur_start = 0\n",
    "cur_finish = 0\n",
    "last = len(t)\n",
    "group_table = {}\n",
    "for i in range(len(t)):\n",
    "    name, start, finish, duration = t.index[i], t.iloc[i].start_time, t.iloc[i].finish_time, t.iloc[i].module_init_duration\n",
    "    print(name, start, finish, duration)\n",
    "\n",
    "    if cur_duration == 0:\n",
    "        num_included = 0\n",
    "        cur_duration = duration\n",
    "        cur_start = start\n",
    "        cur_finish = finish\n",
    "        group_modules = [name]\n",
    "    \n",
    "    cur_finish = max(cur_finish, finish)\n",
    "    cur_duration = cur_finish - cur_start\n",
    "    # print(\"cur_start, cur_finish, cur_duration: {}, {}\".format(cur_start, cur_finish, cur_duration))\n",
    "\n",
    "    # peek the next check if next module passes the thresholds\n",
    "    next_module_pass_threshold = False\n",
    "    if i < last - 1:\n",
    "        next_name, next_start, next_finish, next_duration = t.index[i+1], t.iloc[i+1].start_time, t.iloc[i+1].finish_time, t.iloc[i+1].module_init_duration\n",
    "        next_finish = max(cur_finish, next_finish)\n",
    "        # print(\"next_finish {}, next_finish - cur_start {}\".format(next_finish, next_finish - cur_start))\n",
    "        # if next duration is more than threshold and there is more than one collapsed, then stop collapsing the current modules\n",
    "        if next_finish - cur_start > threshold and num_included > 0:\n",
    "            next_module_pass_threshold = True\n",
    "    \n",
    "    # if cur_duration + duration > threshold:\n",
    "    if cur_duration > threshold or next_module_pass_threshold:\n",
    "        # peek the next one and keep adding until the threshold is reached\n",
    "        # create a new onew\n",
    "        group_name = \"group_{}\".format(n_event)\n",
    "        new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "        print(\"includes {}, added: {}\".format(num_included, new_d))\n",
    "        new_events.append(new_d)\n",
    "        cur_duration = 0\n",
    "        n_event += 1\n",
    "        group_table[group_name] = group_modules if num_included > 0 else [name]\n",
    "        group_modules = []\n",
    "    else:\n",
    "        group_modules.append(name)\n",
    "        num_included += 1\n",
    "        pass\n",
    "            \n",
    "if cur_duration != 0:\n",
    "    group_name = \"group_{}\".format(n_event)\n",
    "    new_d = {\"module_name\" : group_name, \"start_time\" : cur_start, \"finish_time\" : cur_finish, \"module_init_duration\" : cur_duration}\n",
    "    print(\"added: {}\".format(new_d))\n",
    "    new_events.append(new_d)\n",
    "    group_table[group_name] = group_modules\n",
    "\n",
    "new_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_str = group_table['group_6']\n",
    "t_str1 = ','.join(t_str)\n",
    "t_str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_table_str = []\n",
    "for k, v in group_table.items():\n",
    "    dict = {}\n",
    "    dict[\"group_name\"] = k\n",
    "    dict[\"modules\"] = ','.join(v)\n",
    "    group_table_str.append(dict)\n",
    "\n",
    "# display(group_table_str)\n",
    "for d in group_table_str:\n",
    "    print(\"{}: {}\".format(d[\"group_name\"], d[\"modules\"]))\n",
    "\n",
    "for k, v in group_table.items():\n",
    "    print(\"{}:\".format(k))\n",
    "    for m in v:\n",
    "        print(\"  {}\".format(m))\n",
    "    # print(\"{}: {}\".format(d[\"group_name\"], d[\"modules\"]))\n",
    "\n",
    "# group_table_str_df = pd.DataFrame(group_table_str)\n",
    "# group_table_str_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(group_table)\n",
    "# group_table_df = pd.DataFrame.from_dict(group_table, orient='index')\n",
    "# display(group_table_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_events)\n",
    "new_df.set_index('module_name', inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(new_df, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15228333.0 - 15216708.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15257625.0-15228333.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = small_df[-42:]\n",
    "display(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_module_time_chart(t1, small_set=-1, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fa8f9c45b60853bb3d615f814548b5337da45fc6ea40b493b018f80b808d764"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
