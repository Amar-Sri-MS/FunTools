#!/usr/bin/env python3

#
# Processes code coverage sample files (generated by F1/S1).
#
# Coverage sample files contain file, function and counter information in a
# JSON schema. This utility reads in all sample files in the specified
# directory and writes out the .gcda files in the correct paths.
#
# The .gcda locations are specified by gcc during compilation, and typically
# are right next to the object files. The .gcda file format is specified
# in gcc/gcov-io.h.
#
# Usage: process_cov_samples.py -h for help on usage.
#
# Copyright (c) 2019 Fungible Inc. All rights reserved.
#

import argparse
import glob
import json
import os
import io
import struct
import subprocess
import sys
import tempfile

#
# Determine the location of the FunTools repo, or die trying.
#
WS = os.environ.get('WORKSPACE', None)

if WS is None:
    print('Missing WORKSPACE environment variable.')
    sys.exit(1)

FUNTOOLS = os.path.join(WS, 'FunTools')


# GCOV tag constants
GCOV_DATA_MAGIC = 0x67636461
GCOV_VERSION = 0x4138322a  # this needs to change if gcc is upgraded
GCOV_TAG_FUNCTION = 0x01000000
GCOV_TAG_COUNTER_BASE = 0x01a10000

# GCOV length constants
GCOV_FUNCTION_LEN = 3


class GCDAConverter(object):
    """
    Turns the coverage json object into the contents of a GCDA file.

    This object omits the "summary" section of the GCDA file because
    reproducing the code that calculates histograms and checksums is
    annoying. More importantly: omitting the summary section seems
    to be harmless.
    """
    def __init__(self, cov_json):
        self.json = cov_json
        self.fh = io.StringIO()

    def generate_file_contents(self):
        """
        Generates gcda file contents.

        Returns a tuple of (filename, file_contents)
        """
        filename = self.json['filename']

        self._write_tag_and_length(GCOV_DATA_MAGIC, GCOV_VERSION)
        self._write_unsigned(self.json['stamp'])

        for fn in self.json['functions']:
            self._write_function(fn)

        # The magic terminator for a .gcda file (lol)
        self._write_unsigned(0)

        contents = self.fh.getvalue()
        self.fh.close()
        return filename, contents

    def _write_function(self, fn):
        self._write_tag_and_length(GCOV_TAG_FUNCTION, GCOV_FUNCTION_LEN)
        self._write_unsigned(fn['ident'])
        self._write_unsigned(fn['line_chksum'])
        self._write_unsigned(fn['cfg_chksum'])

        for ctr_group in fn['ctr_groups']:
            self._write_counter_group(ctr_group)

    def _write_counter_group(self, ctr_group):
        idx = ctr_group['idx']
        vals = ctr_group['vals']
        num_vals = len(vals)
        self._write_tag_and_length(self._get_counter_tag(idx),
                                   self._get_counter_length(num_vals))
        for val in vals:
            self._write_counter(val)

    def _get_counter_tag(self, counter):
        return GCOV_TAG_COUNTER_BASE + (counter << 17)

    def _get_counter_length(self, num_vals):
        return num_vals * 2

    def _write_tag_and_length(self, tag, length):
        self._write_words([tag, length])

    def _write_words(self, words):
        """
        Write all 32-bit words in the words array.
        """
        for w in words:
            s = struct.pack('I', w)
            self.fh.write(s)

    def _write_unsigned(self, val):
        self._write_words([val])

    def _write_counter(self, val):
        """
        Counters are written low 32-bit word first
        """
        self._write_words([val & 0xffffffff,
                           (val >> 32) & 0xffffffff])


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('input_dir', type=str,
                        help='Directory containing the coverage samples')
    args = parser.parse_args()

    glob_path = os.path.join(args.input_dir, 'cov_data_*')
    sample_files = glob.glob(glob_path)
    sample_files.sort()

    process_sample_files(sample_files)


def process_sample_files(sample_files):
    """
    Processes all sample files and writes the results to the
    specified file handles.
    """
    for sample_file in sample_files:
        cov_json = read_bjson(sample_file)

        if cov_json is None:
            continue
        converter = GCDAConverter(cov_json)
        filename, contents = converter.generate_file_contents()
        with open(filename, 'wb') as fh:
            fh.write(contents)


def read_bjson(sample_file):
    """
    Reads a sample file and returns a json object.

    The sample files are encoded with a custom binary JSON scheme.
    This function decodes the binary JSON to text JSON.
    """
    _, tfile = tempfile.mkstemp('_json', 'converted_')
    jsondir = os.path.join(FUNTOOLS, 'jsonutil')
    jsonutil_binary = os.path.join(jsondir, 'jsonutil')
    cmd = [jsonutil_binary, '-I', sample_file, '-o', tfile]
    try:
        subprocess.check_output(cmd)
    except subprocess.CalledProcessError as e:
        print('Skipping file %s: conversion from binary JSON '
               'failed with %s' % (sample_file, e.output))
        return

    with open(tfile, 'r') as fh:
        json_obj = json.load(fh)

    os.remove(tfile)
    return json_obj


if __name__ == '__main__':
    main()
